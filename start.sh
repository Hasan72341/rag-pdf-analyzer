#!/bin/bash

echo "üöÄ Starting GenAI Development Environment..."

# Function to start a service in the background
start_service() {
    local service_name="$1"
    local command="$2"
    echo "Starting $service_name..."
    eval "$command" &
}

# Start Jupyter Lab
start_service "Jupyter Lab" "jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=genai-dev-token"

# Start Code Server (VS Code in browser)
start_service "Code Server" "code-server --bind-addr 0.0.0.0:8080 --auth password"

# Print access information
echo ""
echo "üéâ GenAI Development Environment is starting up!"
echo ""
echo "üìä Services will be available at:"
echo "   ‚Ä¢ Jupyter Lab:    http://localhost:8888 (token: genai-dev-token)"
echo "   ‚Ä¢ VS Code Server: http://localhost:8080 (password: genai-dev-password)"
echo "   ‚Ä¢ Streamlit:      http://localhost:8501"
echo "   ‚Ä¢ Gradio:         http://localhost:7860"
echo "   ‚Ä¢ FastAPI/Flask:  http://localhost:5000"
echo "   ‚Ä¢ General Web:    http://localhost:3000"
echo ""
echo "üíæ Database services:"
echo "   ‚Ä¢ PostgreSQL:     localhost:5432 (user: genai_user, db: genai_db)"
echo "   ‚Ä¢ Redis:          localhost:6379"
echo "   ‚Ä¢ Elasticsearch:  http://localhost:9200"
echo "   ‚Ä¢ Qdrant:         http://localhost:6333 (REST API)"
echo "   ‚Ä¢ Ollama:         http://localhost:11434 (LLM API)"
echo ""
echo "üìÅ Workspace structure:"
echo "   ‚Ä¢ /workspace/projects  - Your AI projects"
echo "   ‚Ä¢ /workspace/data      - Datasets and data files"
echo "   ‚Ä¢ /workspace/models    - Trained models and checkpoints"
echo "   ‚Ä¢ /workspace/notebooks - Jupyter notebooks"
echo ""
echo "üîß Useful commands:"
echo "   ‚Ä¢ pip install <package>     - Install Python packages"
echo "   ‚Ä¢ python your_script.py     - Run Python scripts"
echo "   ‚Ä¢ streamlit run app.py      - Run Streamlit apps"
echo "   ‚Ä¢ python -m gradio app.py   - Run Gradio apps"
echo "   ‚Ä¢ ./setup-models.sh         - Download AI models (Qwen, Llama, etc.)"
echo "   ‚Ä¢ ollama list               - List installed models"
echo "   ‚Ä¢ ollama run qwen2.5:7b     - Chat with models directly"
echo ""

# Keep the container running
echo "‚úÖ Environment ready! Press Ctrl+C to stop all services."
wait